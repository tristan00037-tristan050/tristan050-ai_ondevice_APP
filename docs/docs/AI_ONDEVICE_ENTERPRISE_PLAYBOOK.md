> 이 문서는 AI 온디바이스 Enterprise OS의 **공식 개발·검토 기준 문서(v1)**입니다.  
> 투자사/임원용이 아니라, **웹(ops-console) / 앱(app-expo HUD) / 서버(BFF + 서비스 코어 + DB)** 전 구성원이  
> 모든 기능·PR·스프린트에서 따라야 하는 내부 지침서입니다.  
> 다른 문서와 충돌할 경우, 이 문서의 원칙을 우선합니다.


# AI 온디바이스 기업용 플랫폼 – Enterprise Playbook  
(웹·앱·내부 서버 공통 개발 방향 고정 문서)

---

## 0. 한 줄 요약 – 무엇을 만들고 있는가

> **“개인 PC·브라우저·사내 태블릿 위에서 돌아가는 온디바이스 AI 에이전트 + 회사 내부망에만 붙는 AI 게이트웨이(OS)”**

펫샵/소매용 서비스가 아니라,  
**국내외 일반 기업**이 내부 정보 유출 걱정 없이  
회계·CS·HR·기획·보안 업무를 자동화/보조할 수 있는 **기업용 OS 레이어**를 만든다.

이 문서는 **웹(ops-console) / 앱(app-expo HUD) / 서버(BFF + 서비스 코어 + DB)** 전 구성원이  
같은 방향을 유지하기 위한 “개발 방향 고정 지시서 + Playbook”이다.

---

## 1. 제품 정의 – 기업이 실제로 쓰는 기능 관점

### 1-1. 온디바이스 레이어 (웹·앱 공통)

* 직원 PC/노트북/브라우저/태블릿에서 돌아가는 **AI 업무 비서**
  * 문서·메일·지출·보고서·로그를 **로컬에서 요약/정리/검토**.
  * 지출/분개/대사 HUD처럼, **특정 업무 흐름에 맞는 특화 UI(HUD)** 제공.
* 원칙:
  * **원본 데이터(문서/텍스트/오디오)는 기기 밖으로 나가지 않는다.**
  * 필요 시에만 **“요약/통계/지표”만 내부 서버로 보낼 수 있다.**
  * 온디바이스 LLM/룰 엔진이 기본값이며, 외부 SaaS LLM은 예외적 옵션이다.

### 1-2. 내부 서버(기업 OS 게이트웨이) 레이어

* 역할:
  1. **정책/권한/조직 정보**  
     누가, 어느 데이터에 접근·질문·승인할 수 있는지.
  2. **감사 로그**  
     누가, 언제, 무엇을 보고/승인/수정했는지.
  3. **사내 시스템(ERP/메일/CS/Drive) 연동**  
     온디바이스가 직접 외부로 나가지 않게 대신 호출.
  4. **AI 모델·지식 베이스 관리**  
     어떤 모델/버전/지식 소스를 쓸지 통제.
* 서버는 **“AI 코어”가 아니라 “정책·로그·연동”이 역할**이다.

---

## 2. 현재 기준선 – 어디까지 와 있는가 (R7~R9)

### 2-1. 웹 (ops-console / web-core)

* R7 기준 웹 코어:
  * “회계 모듈 v0 + 관제용 Backoffice” 완성.
  * `/demo/accounting` 데모 페이지 +  
    파일럿용 Dashboard / Audit / Export / Recon 화면 구성.
* 파일럿/운영용 리포트:
  * `report_pilot_metrics.mjs` – Top-1, Top-5, Manual Review 비율 등.
  * `report_adapter_slo.mjs` – 어댑터 SLO/에러율 리포트.

### 2-2. 앱 (app-expo / HUD)

* HUD Web 모드(Mock / Live) 모두 기동 가능:
  * Mock:  
    `npm run demo:app:mock` → **BFF 없이 UX·플로우만 검증**
  * Live:  
    `docker compose up -d db bff` +  
    `npm run demo:app:live` → **BFF와 실제 통신**
* 회계 HUD:
  * 분개/승인/Export/대사 Flows + Offline Queue + 에러 UX.
* CS HUD:
  * R9-S1: CS 티켓 v1 도메인 + HUD/BFF/OS 카드 1차 연동.
  * R9-S2: SuggestEngine + LocalLLMEngineV1 Stub(온디바이스 LLM 모드 골격) 연동.

### 2-3. 서버 (bff-accounting + service-core-accounting + data-pg)

* R7-H 파일럿 기준 주요 API:
  * `/v1/accounting/postings/suggest`
  * `/v1/accounting/approvals/*`
  * `/v1/accounting/exports/reports`
  * `/v1/accounting/reconciliation/*`
  * 외부 어댑터 sync (`external_ledger_*`, `external_sync_*` audit 이벤트)
* PostgreSQL 마이그레이션, 감사 로그,  
  OS 정책 브리지(`X-User-Role`, `X-Tenant`, `X-User-Id`)까지 연결.
* CS 도메인:
  * R9-S1: `cs_tickets` 도메인 + HUD/BFF/OS 카드.
  * R9-S2: CS LLM 컨텍스트/응답 타입 + SuggestEngine/LocalLLM Stub 연동 진행 중.

> **지금부터는 이 상태를 기준선으로 삼고, 기능을 늘리되 방향을 틀지 않는다.**

---

## 3. 공통 개발 원칙 (웹·앱·서버 전부)

### 3-1. 온디바이스 우선

* 모델 호출, 요약/정리/추천은 **가능한 한 웹/앱에서 실행**한다는 가정으로 API·UI 설계.
* 서버는 **AI 연산을 대신하는 곳이 아니라**,  
  **정책·로그·외부 시스템 연결**에 집중한다.

### 3-2. 사내망 게이트웨이 우선

* 외부 은행/PG/3rd-party API 등은 **항상 내부 BFF에서만 호출**.
  * 웹/앱이 인터넷으로 직접 나가면 안 됨.
* Live 모드에서도 구조는 고정:
  * `클라이언트 (HUD/Web) → BFF → 외부 시스템`

### 3-3. OS 정책 브리지 고정

모든 API 요청에는 반드시 다음 헤더가 포함된다:

* `X-Tenant`
* `X-User-Id`
* `X-User-Role`

원칙:

* 앱/웹에서 이 헤더가 누락된 채 **새 API를 추가하지 말 것.**
* 테스트 코드(E2E, offline-queue 등)도 항상 이 구조에 맞춰 수정.

### 3-4. Mock / Live 항상 쌍으로 유지

* 앱(HUD), 웹(ops-console), 스크립트 모두:
  * Mock 모드: **온디바이스만으로 플로우가 동작**해야 한다.
  * Live 모드: 같은 플로우를 **BFF + DB 기준**으로 검증해야 한다.
* 새 기능 추가 시:
  * **Mock 브랜치 / Live 브랜치를 같이 손대는 것**을 기본으로 생각할 것.

---

## 4. 데이터 등급·보안·컴플라이언스

### 4-1. 데이터 등급 정의 (예시)

* **Public**: 공개 자료, 가이드 문서, 마케팅 자료 등  
* **Internal**: 일반 사내 문서, 회의록, 업무 매뉴얼 등  
* **Confidential**: 재무 데이터, 인사 관련 문서, 계약서 초안 등  
* **Restricted**: 법적 분쟁 자료, 극비 전략, 일부 인사/의료 정보 등

### 4-2. 온디바이스 처리 원칙

* 온디바이스 LLM/룰 엔진은 기본적으로 **Internal까지**를 기본 대상으로 한다.
* **Confidential 이상**은:
  * 명시적으로 허용된 HUD/워크플로우에서만 접근.
  * 기본값은 “불필요하면 읽지 않는다”.
* **Restricted 등급**은 원칙적으로 이 플랫폼 입력에서 **제외**.

### 4-3. 서버 전송 원칙

* BFF/게이트웨이에는 가능한 한 **요약/통계/지표만** 보낸다.
* 원문 텍스트/파일이 서버로 넘어가야 하는 경우:
  * 관련 API는 “특수 플로우”로 분리,
  * 로그/감사·보존·삭제 정책을 함께 정의한다.

### 4-4. 로그·감사·보존

* 모든 주요 행위:
  * “누가(tenant/user/role) 언제 무엇을 질문/조회/승인/실행”했는지 구조화 로그로 남긴다.
* 보존 정책:
  * 파일럿/개발 환경: 짧은 보존 + 샘플링 허용.
  * 상용/운영 환경: 규제·회사 정책에 맞는 보존 기간/삭제 절차 적용.

---

## 5. 멀티테넌시·조직·역할 모델

### 5-1. 테넌트 경계

* 서로 다른 회사(테넌트) 데이터는 **DB 레벨에서 명확히 분리**하는 것을 원칙으로 한다.
* 최소 기준:
  * 대부분의 핵심 테이블에 `tenant` 컬럼 포함.
  * 주요 쿼리에서 항상 `WHERE tenant = :tenant` 조건이 포함.

### 5-2. 조직/역할 모델

* 기본 역할:
  * `operator`, `auditor`, `admin` 3 레벨을 기본값으로 한다.
* 도메인 확장:
  * 회계/CS/HR/법무/보안 등 도메인별 역할 세분화를 허용하되,
  * `X-User-Role`은 항상 이 상위 구조와 매핑 가능해야 한다.

### 5-3. SSO/IdP 연동 전제

* 중장기적으로 SSO/IdP 기반 인증/SCIM 프로비저닝을 전제로 한다.
* `user_id`, `tenant`, `role`은 외부 IdP claim과 자연스럽게 매핑될 수 있도록 설계한다.

5-4. BFF 라우트 헤더 정책 일관성

- 회계(`/v1/accounting/*`), CS(`/v1/cs/*`), HR/법무/보안/공정 등
  모든 도메인 BFF 라우트는 공통으로 다음 헤더 규칙을 따른다.
  - X-Tenant
  - X-User-Id
  - X-User-Role
- 각 도메인 라우트는 `requireTenantAuth`, `requireRole(...)` 등의 가드를 통해
  동일한 헤더/권한 모델을 강제한다.


---

## 6. 모델·지식 베이스 거버넌스

### 6-1. 모델 명명 및 버전 정책

* 모델/엔진 이름 예시:
  * `rule`, `local-llm-v1`, `local-llm-v2`, `remote-llm-x` 등.
* 코드/설정/로그 어디에서나 **동일한 이름**으로 식별 가능해야 한다.
* 롤백·캔어리 롤아웃을 전제로 모델 버전 설계를 한다.

### 6-2. 모델 배포 원칙

* 새 모델/프롬프트는 항상 **도메인별 평가 세트**로 테스트 후 배포:
  * 회계 도메인: 분개 추천, 대사 결과 요약 등.
  * CS 도메인: 티켓 요약, 답변 추천 등.
* dev → pilot → prod 3단계 이상 환경을 기본 전제로 한다.

### 6-3. 지식 베이스·커넥터

* ERP/메일/Drive/티켓 시스템 등 커넥터별로:
  * 어떤 데이터가 인덱싱 대상인지,
  * 어느 테넌트/부서가 접근 가능한지,
  * 동기화 주기/보존 기간이 어떻게 되는지
  를 문서 + 설정으로 강제한다.

  6-4. Remote LLM 모드 원칙

- `engine_mode = remote` 또는 이에 상응하는 원격 LLM 호출은
  **항상 사내 게이트웨이(BFF/OS Gateway)를 경유해야 한다.**
- HUD/Web 클라이언트는 외부 LLM(예: OpenAI, Gemini, 기타 SaaS)에
  직접 HTTP 호출을 날리지 않는다.
- 게이트웨이는 다음을 담당한다:
  - 외부 LLM API 키/엔드포인트 관리
  - 요청/응답 로깅 및 마스킹
  - 테넌트/조직/권한 및 데이터 경계 정책 적용


---

## 7. 웹 (ops-console) 개발 지시

### 7-1. 현재 스코프

* 회계 모듈 Backoffice:
  * `/demo/accounting`
  * Audit 이벤트 리스트, Export Job, Recon 세션 개요
  * 파일럿/운영용 리포트는 별도 scripts  
    (`report_pilot_metrics.mjs`, `report_adapter_slo.mjs`)

### 7-2. 바로 이어서 할 작업

1. **회계 데모 페이지 UX 고도화**
   * `/demo/accounting`에서:
     * 파일럿 지표(Top-1, Top-5, Manual Review 비율)를  
       시각적으로 보여줄 Card/그래프 추가.
     * “샘플 데이터 시드 실행 여부”를 한눈에 알 수 있도록 표시.

2. **역할/테넌트 별 UI**
   * `X-User-Role=operator/auditor` 등에 따라:
     * Export / Audit / Recon 메뉴 표시/숨김.
   * 실제 권한 기능이 완벽하지 않아도  
     **UI 레벨에서 역할 개념 체험 가능**하게 만드는 것이 목표.

3. **기업 OS 관점 메뉴 구조 유지**
   * 메뉴/라우트 이름은 **회계용 기능 기준**:
     * 예: `Accounting / OS Dashboard / Audit / External Sources`
   * 펫샵/소매용 문구(예: 매장, 입양 등)는 웹 쪽에서는 쓰지 않는다.

4. **웹은 “내부 사원용 콘솔”**
   * 외부 고객용 사이트가 아니다.
   * 기업 내부 팀(회계/재무/운영)이 쓰는 **사내 콘솔**이라는 전제를 절대 깨지 않는다.

---

## 8. 앱 (app-expo / HUD) 개발 지시

### 8-1. 모드 구분 (고정 규칙)

* **Mock 모드** (`npm run demo:app:mock`)
  * 외부 네트워크(HTTP) 호출 없음.
  * 모든 API 함수는 `[MOCK] ...` 로그만 남기고 내부에서 처리.
  * 목적:
    * UI/UX/동선/텍스트/컴포넌트 상태를 **온디바이스만으로** 테스트.

* **Live 모드** (`npm run demo:app:live`)
  * BFF(`http://localhost:8081`)와 실제 통신.
  * OS 정책 헤더, CORS, Rate Limit, DB 연결까지  
    **진짜 운영 플로우를 검증**.

### 8-2. HUD 개발 시 필수 체크포인트

1. **새 버튼/기능 추가 시**
   * 항상 **Mock 분기부터 먼저 작성**:
     ```ts
     if (cfg.mode === 'mock') {
       // 온디바이스 Stub / 더미 데이터
     } else {
       // Live 분기
     }
     ```
   * Live 분기는 기존 `mkHeaders` / OS 정책 / Offline Queue 패턴에 맞춰 추가.

2. **Offline Queue는 “항상 안전”하게**
   * 실패는 전제이다.
   * 원칙:
     * 큐 길이 증가/감소가 **눈에 보이도록** 유지(QueueBadge 등).
     * 4xx/5xx는 HUD 에러 메시지 + 콘솔 로그로 남기고,
       **무한 재시도 금지**.

3. **디자인/레이아웃 기준**
   * “기업용 앱 코어” UI/UX는 HUD에서 쓰는 패턴  
     (Button/Text/Input/Badge 등)을 **공통 컴포넌트**로 추출해서 재사용하는 것을 목표로 한다.

---

## 9. 서버 (BFF + 서비스 코어 + DB) 개발 지시

### 9-1. 역할 정리 (다시 강조)

* **BFF**는 AI 모델 서버가 아님:
  * 인증/권한/테넌트·역할 맵핑 (OS 정책 브리지).
  * 외부 시스템(은행/PG/ERP/메일)과의 연결.
  * 감사 로그/리포트/파일럿 지표 수집.

* **service-core-accounting (및 각 도메인 service-core)**:
  * 도메인 로직(분개, 대사, Export 준비, Risk 엔진 등).
  * 도메인 규칙은 여기서만 바꾸고, BFF는 thin하게 유지.

* **data-pg**:
  * DB 접근/쿼리/마이그레이션.
  * 새 테이블/뷰 추가 시,  
    **먼저 마이그레이션 + repo 코드부터 작성** 후 서비스/라우트에서 참조.

### 9-2. 개발 시 Do / Don’t

* **Do:**
  * 모든 API는 **OS 정책 헤더 검사** 통과 후에만 로직 진입.
  * 마이그레이션 추가 시:
    * `npm run db:migrate`
    * `scripts/check_audit_events.sql` 등으로 검증.
  * 로그는 항상 **구조화(JSON)** + `tenant`, `request_id`, `idem` 포함.

* **Don’t:**
  * 클라이언트(웹/앱)가 직접 외부 은행/PG/3rd API를 호출하게 만들지 말 것.
  * 문제를 숨기기 위해 `declare module ... d.ts`로 TS 에러를 통째로 뭉개지 말 것.  
    (경량 타입 우회는 허용하되, 모듈 자체를 “아무 타입”으로 덮는 것은 금지.)

---

## 10. 운영·관측·품질 (SLO)

### 10-1. 공통 SLO 지표

* HUD 응답 시간:
  * Mock 모드 기준 **1초 이내**
  * Live 모드 기준 **2초 이내**를 목표로.
* BFF API 오류율:
  * 1분 슬라이딩 윈도우 기준 **1% 미만** 유지.
* Mock 모드 네트워크:
  * HTTP/WS 요청 **0건** 유지 (정책 불변).

### 10-2. 관측 데이터

* 모든 주요 경로(HUD → BFF → 외부 어댑터)는:
  * `request_id`, `tenant`, `user_id`, `engine_mode(rule/local-llm/remote-llm)` 등을 포함한 구조화 로그를 남긴다.
* 파일럿/운영 환경에서는:
  * Top-1/Top-5 정확도, Manual Review 비율 등 핵심 지표를
  * **일 단위/주 단위 리포트 스크립트**로 자동 생성하는 것을 기본으로 한다.

### 10-3. 알림·대응

* SLO 위반(오류율 급증, 응답 시간 지연 등) 시:
  * 어느 채널(Slack/메일 등)로,
  * 누구에게(운영팀/개발팀/보안팀) 알릴지 기본 룰을 정해둔다.
* 파일럿 단계에서는 수동 모니터링 + 주기 리포트,  
  상용 단계에서는 자동 알림으로 전환하는 것을 목표로 한다.

---

## 11. 단계별 로드맵 – 개발팀이 따라야 할 순서

### 11-1. 지금~단기 (R7-H 안정화 구간)

1. **회계 파일럿 안정화**
   * HUD(Mock/Live), 웹 데모(`/demo/accounting`),  
     리포트 스크립트(Top-1/Top-5/SLO)를 기준으로
   * “사내 회계팀이 써볼 수 있는 수준”까지 에러/경계 케이스 제거.

2. **데모 루틴 고정**
   * 아래 4개 명령이 **언제 돌려도 같은 결과** 나오는 상태를 만든다:
     * `npm run demo:seed`
     * `npm run demo:web`
     * `npm run demo:app:mock`
     * `npm run demo:app:live`

### 11-2. 중기 (R8-S1 이후)

1. **RiskScoreEngine v1 (고액 거래 필터)**
   * 지금 추가된 인터페이스 기준:
     * HIGH_VALUE 거래를 먼저 잡는 엔진 구현.
     * HUD/Backoffice에서 HIGH 레벨 표시 + 수동 검토 강제.

2. **다른 부서로 확장 설계**
   * HR/CS/법무/보안 중 어느 도메인을 두 번째로 가져갈지 결정 후,
   * 회계에서 쓴 구조(HUD + Backoffice + BFF + Report)를 **그대로 재사용**.

---

## 12. 개발팀에 대한 최종 지시

1. **“펫샵 전용” 기능은 이 레포에 넣지 않는다.**
   * 이 레포는 **기업용 온디바이스 OS 코어 전용**이다.

2. 모든 새 기능은 다음 네 가지를 기준으로 설계한다.
   * 온디바이스에서 먼저 돌 수 있는지.
   * 내부 BFF/게이트웨이가 책임질 부분이 무엇인지.
   * OS 정책/권한/감사 로그가 빠지지 않았는지.
   * Mock 모드 / Live 모드를 모두 고려했는지.

3. 웹 / 앱 / 서버는 “따로”가 아니라 “역할 분담”이다.
   * 웹: 내부 직원 콘솔(Backoffice)
   * 앱: 현장/개인 PC에서 쓰는 HUD
   * 서버: 기업 OS 게이트웨이 (정책·로그·연동)

4. 지금부터 새 작업을 시작할 때마다,  
   PR/커밋 설명에 꼭 다음 문장 중 하나를 포함한다.
   * “이 기능은 **어떤 부서/역할(회계/CS/HR/보안)**이 온디바이스로 무엇을 할 수 있게 만드는가?”
   * “이 변경은 내부 서버(게이트웨이)가 어떤 책임을 추가로 지는가?”
   * “이 변경이 Mock/Live 모드, 온디바이스/게이트웨이/외부 시스템 간 **경계를 어떻게 강화하거나 변경**하는가?”

   ## Enterprise Playbook

- `docs/AI_ONDEVICE_ENTERPRISE_PLAYBOOK.md`  
  - 웹/앱/BFF/서비스 코어/DB 공통 개발 방향 고정 지시서
  - 모든 새 기능 설계/PR 시 이 문서를 기준으로 판단

> 이 Playbook을 기준으로,  
> 기능 하나를 추가할 때마다 **“기업 온디바이스 OS에 어떤 기여를 하는지”**를 먼저 설명하고  
> 설계·코드·테스트를 진행한다.


# AI 온디바이스 Enterprise OS – 핵심 Q&A (초안 by 검토팀)

> 목적  
> - 지금 우리가 만들고 있는 “AI 온디바이스 Enterprise OS”의 **개념과 방향을 내부적으로 한 번 더 고정**하기 위함이다.  
> - 국내외 경쟁, 차별화, 해외 진출을 염두에 두고 “어떤 OS를 만들고 있는지”를 개발·아키텍처 관점에서 정리한다.  
> - 투자사/임원 제안서가 아니라, **개발·검토팀이 항상 참고할 기준 문서**이다.

---

## Q1. 우리는 뭘 만들려고 하나요? (한 줄 정의)

### 요약 답변

**“회계·CS·HR·법무·보안·핵심 기술·제조·소프트웨어·개인정보 등 여러 업무 HUD를  
하나의 규격으로 올려 돌리는, 온디바이스 우선 + 사내 게이트웨이 기반의 Enterprise AI OS 레이어”**

### 상세 설명

- **OS 레이어**  
  - 특정 앱/챗봇 하나가 아니라,  
    각 부서 HUD(회계 HUD, CS HUD, HR HUD, 법무 HUD, 보안 HUD, 반도체 공정 HUD, 조선 설계 HUD 등)가  
    공통 규칙과 공통 인프라 위에서 돌아가는 **업무용 운영층(Operating System)** 을 지향한다.
- **온디바이스 우선(On-device first)**  
  - 요약·정리·추천·추론은 가능한 한 **직원 PC/브라우저/태블릿에서 직접 수행**하는 것을 기본값으로 한다.
  - 서버는 AI 연산 코어가 아니라, **정책·로그·사내 시스템 연동·감사**가 역할이다.
- **사내 게이트웨이(Enterprise Gateway)**  
  - ERP/메일/CS/Drive/공정 시스템/소스코드 저장소/보안 시스템 등  
    모든 사내·외부 시스템에 대한 접근은 **게이트웨이가 단일 창구로 담당**한다.
  - 인증/권한/조직/테넌트, 감사 로그, 외부 API 호출 정책은 모두 게이트웨이 기준으로 설계한다.
- **적용 범위**  
  - 단일 회사용이 아니라,  
    **지주사 + 계열사 전체**를 대상으로 하는 전사/전계열 OS 레이어를 목표로 한다.

---

## Q2. 누가 제일 먼저 써야 합니까? (1차 검증 도메인과 장기 타깃)

### 요약 답변

- **1차 검증 도메인**: 회계(지출·분개·대사) + CS(티켓 응답·요약)  
- **장기 타깃 도메인(Vertical)**:  
  - 재무/회계  
  - CS/고객지원  
  - 핵심 기술/제조: 반도체 공정·설계, 조선/해양/플랜트 등  
  - 소프트웨어·보안·개인정보: 중요 소프트웨어 개발, 보안/로그, 개인정보 처리  
  - HR/조직: 인사·채용·배치·평가

### 상세 설명

1. **1차 검증 도메인 – 회계 + CS**

   엔지니어링 관점에서, OS 코어 패턴을 검증하기에 가장 적합한 두 가지 도메인이다.

   - 회계:
     - 숫자·분개·지출·대사 등 **강하게 구조화된 데이터와 규칙**을 가진 영역.
     - 룰 엔진 + LLM 혼합 구조, 리스크/규제 도메인과의 연결을 시험하기 좋다.
   - CS:
     - 티켓, 메일, 대화 로그 등 **비정형 텍스트 중심**의 영역.
     - LLM 기반 요약·응답 추천 패턴을 검증하기 적합하다.

   이 두 도메인을 먼저 뚫으면,
   - “구조화 데이터 + 비정형 텍스트”를 모두 다루는 **OS 공통 패턴**을 확보할 수 있고,
   - 이후 반도체·조선·HR·법무·보안 등으로 확장할 때 재사용 가능한 구조를 가진다.

2. **장기 타깃 도메인 – 고가치 산업 Vertical**

   OS 코어의 설계 타깃으로 명시해 두어야 할 주요 도메인들은 다음과 같다.

   - **재무/회계 도메인 (현재 진행 중)**  
     - 지출/분개/대사/결산/리스크 관리
   - **CS/고객지원 도메인 (현재 진행 중)**  
     - 멀티채널 티켓 처리, 응답 추천, 품질/감독
   - **핵심 기술/제조 도메인**  
     - 반도체 공정·설계: 공정 로그/수율/레시피·PDK/설계 리뷰  
     - 조선/해양/플랜트: 도면/규격/클래스 규정/시험 리포트
   - **소프트웨어·보안·개인정보 도메인**  
     - 중요 소프트웨어 개발: 코드 리뷰, 장애/사고 분석, 아키텍처 문서 관리  
     - 보안/로그: 보안 이벤트/접근 로그/EDR 로그 요약, 이상행위 후보 탐지 보조  
     - 개인정보: 처리 흐름, 위험 시나리오 탐지 보조
   - **HR·조직 도메인**  
     - 인사평가, 채용, 배치, 교육, 피드백 요약 등

   이 도메인들은 모두
   - **극도로 민감한 내부 지식/설계/IP**를 다루고,
   - **문서/로그/도면/코드가 복잡**하며,
   - 대체로 **중대형 기업 + 규제 환경**이라는 공통점이 있어  
     온디바이스 OS + 사내 게이트웨이 구조와 매우 잘 맞는다.

---

## Q3. 그 팀이 뭐가 좋아집니까? (내부 검증용 KPI 2~3개)

### 요약 답변

OS를 도입했을 때, 각 도메인에서 우리가 내부적으로 검증해야 할 대표 KPI는 다음과 같다.

1. **업무 처리 속도(Throughput / Lead Time)**  
2. **사람이 직접 손대는 비율(Manual Touch Rate) 감소**  
3. **품질/리스크 관점 안정성**

### 상세 설명

1. **업무 처리 속도**

   - 회계:
     - 분개·지출·대사 건당 처리 시간 **20~30% 단축**을 목표.
     - HUD에서 추천·자동 채우기·검증을 하고, 사람은 승인/예외 처리 위주로 전환.
   - CS:
     - 1차 응답 시간 **20% 이상 단축**.
     - 템플릿/LLM 추천을 통해 응답 준비 시간을 줄이는 방향.

2. **Manual Touch Rate 감소**

   - 회계:
     - “규칙 기반/LLM 추천만으로 처리 가능한 건”의 비율을 높이고,  
       사람이 보는 케이스는 **고위험/예외** 중심으로 이동.
   - CS:
     - FAQ성/반복 티켓은 LLM 초안 + HUD 추천 비율을 높이고,  
       사람이 개입하는 비율은 난이도 높은 케이스 중심으로 유지.

3. **품질/리스크 측면**

   - 회계:
     - 고위험 거래 누락률 감소, 수동 대사에서 발생하는 실수 감소.
   - CS:
     - 응답 편차(상담사마다 품질 차이) 감소, 클레임/재문의율 감소.
   - 향후 반도체/조선/소프트웨어/보안/HR 도메인에서도  
     “도메인별 품질/리스크 지표”를 OS 수준에서 정의하고 추적할 수 있어야 한다.

---

## Q4. 왜 ‘온디바이스 + 사내 게이트웨이’여야 합니까?

### 요약 답변

1. **데이터 경계 통제** – 반도체 공정/설계, 조선, 중요 SW, 개인정보, HR 데이터는 외부 LLM에 올리기 어렵다.  
2. **사내 시스템 연동의 복잡도를 OS/게이트웨이에서 흡수**해야 한다.  
3. **모델·엔진 전략(국내외 LLM, 현지 규제 등)에 대한 유연성**을 확보하기 위해서다.

### 상세 설명

1. **데이터 경계 통제 (Data Boundary Control)**

   - 우리가 겨냥하는 도메인은 **내부 극비 정보와 민감 데이터**를 다룬다.
     - 반도체 공정 조건/PDK/내부 설계 룰
     - 조선 설계/도면/규격/클래스 인증 자료
     - 중요 소프트웨어 코드/아키텍처/장애 리포트
     - 개인정보/HR 인사 기록 등
   - 이런 데이터는 단순히 “옵션으로 외부 LLM에 보내도 된다/안 된다” 수준이 아니라,  
     **원칙적으로 회사/계열사 경계를 벗어나지 않게 설계해야 하는 클래스**이다.
   - 온디바이스 + 사내 게이트웨이 구조는  
     “**기본값이 내부, 외부는 예외**”인 아키텍처를 구현하기에 적합하다.

2. **사내 시스템 연동의 복잡도 (System Integration Gravity)**

   - 계열사별 ERP/PLM/MES/메일/Drive/CS/소스코드 저장소/보안 시스템이 제각각인 상황에서,  
     클라이언트(HUD)가 각 시스템에 직접 붙으면 관리 불가능해진다.
   - 사내 게이트웨이가 다음을 단일 계층에서 담당하는 것이 필요하다.
     - 인증/권한/테넌트/조직 정책
     - 연결된 사내 시스템별 커넥터
     - 감사 로그 및 규제 대응
   - HUD는 **표준화된 API+정책만 바라보는 클라이언트**로 유지한다.

3. **모델·엔진 전략 유연성 (Model Strategy Flexibility)**

   - LLM 시장은 지역/언어/벤더별로 계속 변하고 있다.
   - 온디바이스/사내 엔진을 기본으로 설계하면:
     - 특정 벤더에 Lock-in 되지 않고,
     - 한국·일본·유럽 등 각 지역에 적합한 **현지 LLM/현지 규제 조합**을 선택할 수 있다.
   - “Rule / Local LLM / Remote LLM” 조합과  
     **도메인·테스크별 엔진 전략**을 OS 레벨에서 통제할 수 있게 된다.

---

## Q5. 누가 돈을 내는 고객(구매자)이 될 것인가? (설계 기준 조직)

### 요약 답변

- **국내 기준**: 지주사/대기업 그룹의 DT/IT/디지털혁신 조직(CIO/CTO/CDO 직속)  
- **해외 기준**: 규제가 강한 산업(금융·보험·의료·제조·방산 등)의 중대형 엔터프라이즈

> 이 질문은 “영업 대상”뿐 아니라  
> **“우리가 설계 기준으로 삼을 요구 수준이 어디냐”**를 정하는 질문이다.

### 상세 설명

1. **국내 기준 – 지주사/대기업 그룹 DT/IT 본부**

   - 전사/전계열 공통 플랫폼을 도입하려면,  
     보안, 규제, 인프라, 조직 구조 요구 수준이 **가장 까다로운 조직**을 기준으로 설계하는 것이 맞다.
   - 이 수준을 만족하도록 설계하면,
     - 단일 회사/중견기업으로 내려갈 때는 **다운스케일**이 가능하지만,
     - 그 반대로는 거의 불가능하다.

2. **해외 기준 – 규제 강한 산업의 중대형 엔터프라이즈**

   - 금융·보험·의료·제조·방산 등은  
     “클라우드 LLM은 부담스럽지만, 업무 자동화를 위해 AI는 써야 하는” 상황에 놓여 있다.
   - 온디바이스 + 사내 게이트웨이 기반 OS는  
     이들 산업에서 **자연스럽게 선택 가능한 구조**다.
   - 따라서 설계 기준은  
     “국내 대기업 그룹”과 “규제 강한 해외 중대형 엔터프라이즈”를 동시에 만족할 수 있는 수준으로 잡는다.

---

## Q6. 우리만의 한 줄 차별점은 무엇인가?

### 요약 답변

**“단순 챗봇/LLM 포털이 아니라,  
온디바이스 HUD + 사내 게이트웨이 + 도메인별 서비스 코어까지 포함한  
‘풀 스택 Enterprise AI OS’”**

### 상세 설명

- 다른 AI 제품들과의 차이:
  - ChatGPT, Copilot, Gemini 등:
    - 주로 **클라우드 LLM + 앱/플러그인** 관점의 제품.
  - 일반적인 사내 LLM 포털:
    - 사내에 LLM/검색을 띄우고, 간단한 프롬프트/도큐먼트 검색을 제공.
- 우리가 지향하는 OS는 다음을 모두 포함한다.
  1. **온디바이스 HUD 레이어**  
     - 회계, CS, HR, 법무, 보안, 반도체 공정, 조선 설계, 중요 SW 개발, 개인정보/보안 HUD 등  
       각 도메인에 특화된 “작업용 운전석(Heads-Up Display)” 레이어.
  2. **사내 게이트웨이 레이어**  
     - 인증/권한/조직/테넌트, 감사, 사내 시스템 연동, 엔진/정책 관리.
  3. **도메인별 서비스 코어 레이어**  
     - 회계/CS/HR/법무/보안/공정 등 각 도메인 로직이 거주하는 서비스 코어.
  4. **엔진 레이어**  
     - Rule/Local LLM/Remote LLM, 도메인/테스크 기반 엔진 라우팅, 모델 버전 관리.

13. 운영 지침 – 검토팀 / 개발팀

13-1. 검토팀 지침 (리뷰 기준)

PR 리뷰 시, 아래 항목을 **최소 한 번씩** 확인한다.

1) 온디바이스 우선 원칙
   - 불필요하게 서버/외부 LLM에 의존하지 않는지
   - `DEMO_MODE=mock`에서 해당 플로우가 온디바이스만으로 동작하는지 (HTTP/WS 0건 유지)

2) 사내 게이트웨이 경계 유지
   - 클라이언트(HUD/Web)가 직접 외부/사내 시스템을 호출하지 않고,  
     반드시 BFF/게이트웨이 경로를 통해 접근하는지
   - X-Tenant, X-User-Id, X-User-Role 헤더/정책이 깨지지 않았는지

3) OS 레이어 재사용성
   - 이번 변경이 특정 도메인(예: 회계, CS)에만 갇히지 않고,
     향후 다음 도메인 HUD에도 재사용 가능한 패턴(엔진/정책/컴포넌트/타입)을 강화하는지:
     - 재무/회계
     - CS/고객지원
     - HR/조직
     - 법무/보안
     - 반도체 공정·설계
     - 조선/해양/플랜트
     - 중요 소프트웨어 개발/보안/개인정보

4) KPI/도메인 적합성
   - “업무 처리 속도 / Manual Touch Rate / 품질·리스크 안정성” 관점에서  
     OS 수준 개선 방향과 맞는지
   - Q&A 섹션(Q3)을 참고하여, 해당 도메인이 가져야 할 KPI와 충돌하지 않는지

검토팀은 이 네 가지를 기반으로  
“이 PR이 AI 온디바이스 Enterprise OS Playbook과 일치하는지”를 최종 판정한다.


13-2. 개발팀 지침 (설계·구현 기준)

새 기능을 설계/구현/PR할 때는 다음을 기본으로 한다.

1) PR 설명에 Enterprise OS 관점 한 줄 포함
   - 예시:
     - `이번 변경은 CS HUD에서 SuggestEngine/LocalLLM 패턴을 검증하여, 이후 HR/법무/보안 HUD에도 재사용 가능한 온디바이스 엔진 구조를 강화합니다.`
     - `회계 HUD에서 사용하던 Offline Queue + OS 정책 패턴을 공통 컴포넌트로 분리하여, 반도체/조선/HR HUD에서도 바로 재사용 가능하게 합니다.`

2) Mock/Live 쌍 유지
   - `DEMO_MODE=mock`:
     - 해당 기능이 온디바이스만으로 동작하는지 반드시 확인한다. (HTTP/WS 요청 0건 유지)
   - `DEMO_MODE=live`:
     - BFF/DB와 실제 통신 플로우를 따라가며,  
       OS 정책 헤더, CORS, Rate Limit, 로그가 정상 동작하는지 확인한다.

3) 도메인 확장 가능성 고려
   - 현재 회계/CS 중심으로 구현하더라도,  
     다음 도메인에 같은 패턴을 적용할 수 있도록 타입/엔진/정책/컴포넌트 구조를 우선적으로 선택한다.
     - 반도체 공정·설계
     - 조선/해양/플랜트
     - 중요 소프트웨어 개발/보안/로그/개인정보
     - HR/조직
   - “이 코드는 나중에 다른 HUD에 그대로 가져다 쓸 수 있는가?”를 항상 스스로 확인한다.

4) Playbook/Q&A를 변경 기준으로 사용
   - 새로운 아키텍처 결정, 새로운 도메인 HUD, 새로운 엔진/모델 전략을 도입할 때는  
     이 Playbook과 Q&A의 정의를 먼저 확인하고,  
     필요 시 이 문서를 함께 업데이트한다.

18. 마무리 – 개발팀 입장 정리

- 본 Playbook 및 검토팀 의견은  
  우리가 지향하는 AI 온디바이스 Enterprise OS 레이어의 **장기 목표와 완전히 일치**하며,  
  개발팀은 이에 대해 **이의 없이 수용**합니다.

- 특히 아래 5가지 축을 R10-S1부터 실제 코드/문서에 반영하는 것을 합의합니다.
  1) 온디바이스 우선 원칙 (local-llm Stub(v0) → 향후 local-llm-v1 실제 모델로의 자연스러운 승격)
  2) 사내 게이트웨이 경계 (HUD/Web → BFF(OS/LLM Gateway) → 외부/사내 시스템/LLM 구조 고정)
  3) OS 레이어 재사용성 (도메인 LLM 추상화, domain→핸들러 레지스트리 패턴, 도메인별 LLM 서비스 공통 인터페이스)
  4) BFF 헤더/권한 정책 일관성 (X-Tenant / X-User-Id / X-User-Role 기반 OS 정책 브리지)
  5) KPI/감사 관점 (처리 속도, Manual Touch Rate, 품질·리스크, LLM 추천 사용/수정/폐기 로그 기반 KPI 설계)

- R10-S1 이후 스프린트에서는 위 5가지 축을 기준으로
  코드/타입/엔진/정책/문서를 순차적으로 보강해 나갈 계획입니다.

- Cursor 및 ChatGPT 기반 개발을 위해,
  모든 제안에는 Cursor에서 바로 사용할 수 있는 명령어와 코드 스켈레톤을 포함하는 것을 원칙으로 합니다.
  (세부 타입/파일 경로는 실제 레포 구조에 맞춰 조정)

- 이후 구체적인 코드/에러/설계안이 주어질 때,
  개발팀과 검토팀, 그리고 ChatGPT 기반 개발/검토는 항상 아래 원칙을 기준으로 판단하고 제안합니다.
  - 온디바이스 우선
  - 사내 게이트웨이 경계 유지
  - Mock/Live 쌍 유지
  - OS 레이어 재사용성 (다도메인 HUD 확장 가능성)
  - 정책/권한/테넌트 일관성
  - 도메인 KPI 및 품질/리스크 지표와의 적합성

