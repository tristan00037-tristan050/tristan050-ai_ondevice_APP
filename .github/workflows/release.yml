name: release-bff

permissions:
  contents: read
  packages: write

on:
  push:
    tags:
      - "r6-*"
      - "r7-*"

jobs:
  build-test-image:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
        working-directory: webcore_appcore_starter_4_17
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: app
          POSTGRES_PASSWORD: app
          POSTGRES_DB: app
        ports:
          - "5432:5432"
        options: >-
          --health-cmd="pg_isready -U app -d app"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=20
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm ci

      - name: Build workspaces
        run: npm run build:packages

      - name: DB migrate
        env:
          DATABASE_URL: postgres://app:app@localhost:5432/app
        run: npm run db:migrate

      - name: Build Docker image
        run: docker build --build-arg GIT_SHA="${{ github.sha }}" -f Dockerfile.bff -t bff-accounting:release .

      - name: Run BFF container
        working-directory: .
        run: |
          set -euo pipefail
          docker rm -f bff >/dev/null 2>&1 || true

          CID="$(docker run -d --name bff -p 8081:8081 \
            --add-host=host.docker.internal:host-gateway \
            -e PORT=8081 \
            -e USE_PG=1 \
            -e DATABASE_URL="postgres://app:app@host.docker.internal:5432/app" \
            -e EXPORT_SIGN_SECRET="ci-secret" \
            bff-accounting:release
          )"
          echo "$CID"

          # NOTE: onprem 표준(/healthz, /readyz)로 통일.
          # host.docker.internal on Linux requires host-gateway mapping (already added). :contentReference[oaicite:0]{index=0}
          for i in $(seq 1 120); do
            if curl -fsS --max-time 2 "http://127.0.0.1:8081/readyz" >/dev/null 2>&1; then
              echo "OK: /readyz"
              break
            fi
            sleep 0.5
            if [ "$i" -eq 120 ]; then
              echo "BLOCK: bff did not become ready"
              echo "== docker ps =="
              docker ps -a || true
              echo "== docker inspect bff =="
              docker inspect bff || true
              echo "== docker logs bff (tail 200) =="
              docker logs --tail=200 bff || true
              exit 1
            fi
          done

          # status-code only (body 출력 0 유지)
          curl -s -o /dev/null -w "HEALTHZ=%{http_code}\n" --max-time 3 "http://127.0.0.1:8081/healthz" || true
          curl -s -o /dev/null -w "READYZ=%{http_code}\n"  --max-time 3 "http://127.0.0.1:8081/readyz" || true

      - name: E2E smoke against container
        env:
          BFF_URL: http://localhost:8081
          TENANT_ID: default
          API_KEY: collector-key:operator
          API_KEY_AUD: collector-key:auditor
        run: |
          set -euo pipefail
          : "${API_KEY:?}"
          : "${API_KEY_AUD:?}"

          npm run test:e2e:accounting:approvals

          # exports는 auditor 권한으로 실행
          API_KEY="${API_KEY_AUD}" npm run test:e2e:accounting:exports

          # exports:neg는 기대 코드(400/422)가 나오려면 operator 키로 돌려야 함(403 오탐 방지)
          API_KEY="${API_KEY}" npm run test:e2e:accounting:exports:neg

          API_KEY="${API_KEY}" npm run test:e2e:accounting:recon

  gate_mobile:
    name: Mobile Gate
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
        working-directory: webcore_appcore_starter_4_17
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: npm ci

      - name: TypeScript check
        run: npm run -w @appcore/app-expo typecheck || echo "typecheck skipped"

      - name: Mobile gate passed
        run: echo "mobile gate passed"

  repo-contracts-gate:
    name: Repo contracts + autodecision gate
    runs-on: ubuntu-latest
    env:
      ONPREM_PROOF_STRICT_ENFORCE: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show checked-out SHA
        shell: bash
        run: |
          set -euo pipefail
          echo "GITHUB_REF=${GITHUB_REF}"
          echo "GITHUB_SHA=${GITHUB_SHA}"
          git rev-parse HEAD
          git show -s --format=%H%n%an%n%ad%n%s HEAD

      - name: Install ripgrep
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y ripgrep jq

      - name: Scan workflow patterns (safe)
        shell: bash
        run: |
          set -euo pipefail
          a="id-"; b="token"
          c="attest"; d="ations"
          e="artifact-"; f="metadata"
          g="attest-build-"; h="provenance"
          rg -n "${a}${b}[[:space:]]*:[[:space:]]*write|${c}${d}[[:space:]]*:[[:space:]]*write|${e}${f}[[:space:]]*:[[:space:]]*write|${g}${h}" .github/workflows || true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Preflight (single source)
        uses: ./.github/actions/preflight_v1

      - name: Show dist build stamp sha
        shell: bash
        run: |
          set -euo pipefail
          STAMP="webcore_appcore_starter_4_17/packages/bff-accounting/dist/.build_stamp.json"
          test -f "$STAMP" || { echo "missing stamp: $STAMP"; exit 1; }
          echo "HEAD=$(git rev-parse HEAD)"
          node -e 'const fs=require("fs"); const j=JSON.parse(fs.readFileSync(process.argv[1],"utf8")); console.log("STAMP.git_sha="+j.git_sha); console.log("STAMP.workflow_name="+j.workflow_name); console.log("STAMP.built_at_utc="+j.built_at_utc);' "$STAMP"

      - name: Ops deps preflight (fail-closed)
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/verify/verify_ops_deps.sh --require-node-npm --require-rg --require-jq

      - name: Install deps (web_e2e)
        shell: bash
        run: |
          set -euo pipefail
          npm --prefix webcore_appcore_starter_4_17/scripts/web_e2e ci

      - name: Install Playwright browsers
        shell: bash
        run: |
          set -euo pipefail
          npx --prefix webcore_appcore_starter_4_17/scripts/web_e2e playwright install --with-deps chromium
        env:
          PLAYWRIGHT_BROWSERS_PATH: ${{ runner.temp }}/ms-playwright

      - name: Generate latest reports (A)
        shell: bash
        run: |
          set -euo pipefail
          bash scripts/ops/gen_repo_guard_report_v1.sh
          bash scripts/ops/run_ai_smoke_v1.sh
        env:
          PLAYWRIGHT_BROWSERS_PATH: ${{ runner.temp }}/ms-playwright

      - name: Generate autodecision (B)
        shell: bash
        run: |
          set -euo pipefail
          node scripts/ops/gen_autodecision_v1.mjs

      - name: Repo contracts gate (always tail on fail)
        shell: bash
        env:
          PLAYWRIGHT_BROWSERS_PATH: ${{ runner.temp }}/ms-playwright
        run: |
          set -euo pipefail
          set +e
          bash scripts/verify/verify_repo_contracts.sh > /tmp/verify_repo_contracts.log 2>&1
          rc=$?
          set -e
          if [ "$rc" -ne 0 ]; then
            echo "BLOCK: verify_repo_contracts failed (rc=$rc)"
            echo "=== tail verify_repo_contracts (last 200 lines) ==="
            tail -n 200 /tmp/verify_repo_contracts.log || true
          else
            cat /tmp/verify_repo_contracts.log
          fi
          exit "$rc"

      - name: Release gate (autodecision must be ok) (C)
        shell: bash
        run: |
          set -euo pipefail
          test -s docs/ops/reports/autodecision_latest.json
          node -e 'const p=require("./docs/ops/reports/autodecision_latest.json"); if(p.decision!=="ok"){console.error("BLOCK: autodecision decision="+p.decision); console.error("reason_codes="+JSON.stringify(p.reason_codes)); process.exit(1)}'

  publish-and-deploy:
    needs: [build-test-image, gate_mobile, repo-contracts-gate]
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & Push image
        working-directory: webcore_appcore_starter_4_17
        run: |
          set -euo pipefail
          REPO_LC="$(echo "${GITHUB_REPOSITORY}" | tr '[:upper:]' '[:lower:]')"
          IMAGE="ghcr.io/${REPO_LC}/bff-accounting"
          TAG="${GITHUB_REF_NAME}"
          docker build --build-arg GIT_SHA="${GITHUB_SHA}" -f Dockerfile.bff -t "${IMAGE}:${TAG}" -t "${IMAGE}:latest" .
          docker push "${IMAGE}:${TAG}"
          docker push "${IMAGE}:latest"

      # setup-helm은 helm만 설치하므로 kubectl은 별도로 설치해야 함. :contentReference[oaicite:1]{index=1}
      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "latest"

      - name: Setup helm
        uses: azure/setup-helm@v4

      - name: "Kubeconfig (robust write: yaml-or-base64, no content output)"
        shell: bash
        env:
          KUBE_CONFIG: ${{ secrets.KUBE_CONFIG }}
        run: |
          set -euo pipefail
          mkdir -p "$HOME/.kube"
          tmp="$(mktemp)"
          trap 'rm -f "$tmp"' EXIT
          printf '%s' "$KUBE_CONFIG" > "$tmp"
          sed -i 's/\r$//' "$tmp" 2>/dev/null || true

          # Detect YAML-ish kubeconfig, else treat as base64 blob.
          if grep -qE '^[[:space:]]*(---[[:space:]]*)?(apiVersion:|kind:[[:space:]]*Config|clusters:|users:|contexts:)' "$tmp"; then
            cp "$tmp" "$HOME/.kube/config"
          else
            base64 -d < "$tmp" > "$HOME/.kube/config" 2>/dev/null || {
              echo "BLOCK: KUBE_CONFIG is not valid kubeconfig YAML and not valid base64"
              exit 1
            }
          fi
          chmod 600 "$HOME/.kube/config"
          echo "KUBECONFIG=$HOME/.kube/config" >> "$GITHUB_ENV"

      # FIX: 기존 kube-norm(v1)은 '키 존재'만 보고 clusters/users null을 놓칠 수 있었음.
      #      아래는 kubectl이 실제로 파싱한 clusters/users/contexts 개수로 fail-closed 판정.
      #      current-context는 use-context로 설정하는 것이 정석. :contentReference[oaicite:2]{index=2}
      - name: Kubeconfig normalize (strict, meta-only)
        shell: bash
        env:
          KUBECONFIG: /home/runner/.kube/config
        run: |
          set -euo pipefail
          echo "[DEBUG] release.yml kube-norm version=2026-02-v2"
          CFG="${KUBECONFIG:-$HOME/.kube/config}"
          echo "[DEBUG] config path=$CFG"

          if [ ! -f "$CFG" ]; then
            echo "BLOCK: kubeconfig file missing"
            exit 1
          fi

          size_bytes="$(wc -c < "$CFG" | tr -d ' ')"
          echo "[DEBUG] size_bytes=$size_bytes"
          if [ "$size_bytes" -lt 200 ]; then
            echo "BLOCK: kubeconfig too small (likely truncated/invalid)"
            exit 1
          fi

          # basic header sanity
          grep -qE '^[[:space:]]*apiVersion:' "$CFG" || { echo "BLOCK: missing apiVersion"; exit 1; }
          grep -qE '^[[:space:]]*kind:[[:space:]]*Config' "$CFG" || { echo "BLOCK: missing kind: Config"; exit 1; }
          grep -qE '^[[:space:]]*clusters:' "$CFG" || { echo "BLOCK: missing clusters:"; exit 1; }
          grep -qE '^[[:space:]]*users:' "$CFG" || { echo "BLOCK: missing users:"; exit 1; }

          # kubectl parse + counts (no content output)
          view_len="$(kubectl config view --kubeconfig "$CFG" -o json 2>/dev/null | wc -c | tr -d ' ' || echo 0)"
          num_clusters="$(kubectl config view --kubeconfig "$CFG" -o jsonpath='{.clusters[*].name}' 2>/dev/null | wc -w | tr -d ' ' || echo 0)"
          num_users="$(kubectl config view --kubeconfig "$CFG" -o jsonpath='{.users[*].name}' 2>/dev/null | wc -w | tr -d ' ' || echo 0)"
          num_contexts="$(kubectl config view --kubeconfig "$CFG" -o jsonpath='{.contexts[*].name}' 2>/dev/null | wc -w | tr -d ' ' || echo 0)"
          cc="$(kubectl config view --kubeconfig "$CFG" -o jsonpath='{.current-context}' 2>/dev/null || true)"
          echo "[DEBUG] config_view_output_len=$view_len num_clusters=$num_clusters num_users=$num_users num_contexts=$num_contexts current_context_len=${#cc}"

          if [ "$num_clusters" -lt 1 ] || [ "$num_users" -lt 1 ]; then
            echo "BLOCK: kubeconfig parses but has null/empty clusters or users"
            exit 1
          fi

          if [ -n "$cc" ]; then
            if kubectl config get-contexts -o name --kubeconfig "$CFG" 2>/dev/null | grep -Fxq "$cc"; then
              echo "OK: current-context already valid (len=${#cc})"
              exit 0
            fi
            echo "BLOCK: current-context set but does not exist in contexts list"
            exit 1
          fi

          if [ "$num_contexts" -ge 1 ]; then
            first_ctx="$(kubectl config get-contexts -o name --kubeconfig "$CFG" 2>/dev/null | head -n1 || true)"
            [ -n "$first_ctx" ] || { echo "BLOCK: contexts present but cannot read first context"; exit 1; }
            kubectl config use-context "$first_ctx" --kubeconfig "$CFG" >/dev/null 2>&1
            echo "OK: set current-context from first context (len=${#first_ctx})"
            exit 0
          fi

          cluster="$(kubectl config view --kubeconfig "$CFG" -o jsonpath='{.clusters[0].name}' 2>/dev/null || true)"
          user="$(kubectl config view --kubeconfig "$CFG" -o jsonpath='{.users[0].name}' 2>/dev/null || true)"
          echo "[DEBUG] first_cluster_len=${#cluster} first_user_len=${#user}"
          [ -n "$cluster" ] && [ -n "$user" ] || { echo "BLOCK: cannot derive cluster/user names to create context"; exit 1; }

          kubectl config set-context ci --cluster="$cluster" --user="$user" --kubeconfig "$CFG" >/dev/null 2>&1
          kubectl config use-context ci --kubeconfig "$CFG" >/dev/null 2>&1
          echo "OK: created and set current-context=ci"

      - name: Kubeconfig sanity check (fail-closed, no content)
        shell: bash
        env:
          KUBECONFIG: /home/runner/.kube/config
        run: |
          set -euo pipefail
          # server가 localhost로 떨어지면 즉시 차단
          server="$(kubectl config view --minify --kubeconfig "$KUBECONFIG" -o jsonpath='{.clusters[0].cluster.server}' 2>/dev/null || true)"
          echo "cluster.server=${server:-<empty>}"
          if [ -z "${server}" ] || echo "${server}" | grep -qE '^https?://localhost:8080'; then
            echo "BLOCK: kubeconfig not loaded (server is empty or localhost:8080)"
            exit 1
          fi

          kubectl --request-timeout=5s get --raw='/version' >/dev/null
          kubectl --request-timeout=5s get --raw='/readyz'  >/dev/null

      - name: Helm upgrade
        run: |
          set -euo pipefail
          REPO_LC="$(echo "${GITHUB_REPOSITORY}" | tr '[:upper:]' '[:lower:]')"

          helm upgrade --install bff charts/bff-accounting \
            --set image.repository="ghcr.io/${REPO_LC}/bff-accounting" \
            --set image.tag="${GITHUB_REF_NAME}" \
            --set env.EXPORT_SIGN_SECRET="${{ secrets.EXPORT_SIGN_SECRET }}" \
            --set env.DATABASE_URL="${{ secrets.DATABASE_URL }}" \
            --wait --timeout 5m
